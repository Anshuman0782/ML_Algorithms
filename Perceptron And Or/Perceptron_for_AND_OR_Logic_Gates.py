import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import Perceptron

# -----------------------------
# Logic Gate Data
# -----------------------------
X = np.array([
    [0, 0],
    [0, 1],
    [1, 0],
    [1, 1]
])

y_and = np.array([0, 0, 0, 1])
y_or  = np.array([0, 1, 1, 1])

# -----------------------------
# Train Perceptron â€” AND Gate
# -----------------------------
and_model = Perceptron(max_iter=1000, eta0=0.1, random_state=0)
and_model.fit(X, y_and)

# -----------------------------
# Train Perceptron â€” OR Gate
# -----------------------------
or_model = Perceptron(max_iter=1000, eta0=0.1, random_state=0)
or_model.fit(X, y_or)

# -----------------------------
# Predictions
# -----------------------------
print("AND Gate Predictions:")
for inp, pred in zip(X, and_model.predict(X)):
    print(inp, "â†’", pred)

print("\nOR Gate Predictions:")
for inp, pred in zip(X, or_model.predict(X)):
    print(inp, "â†’", pred)

# -----------------------------
# Function to Plot Decision Boundary
# -----------------------------
def plot_boundary(model, title):

    w = model.coef_[0]
    b = model.intercept_[0]

    x_vals = np.linspace(-0.5, 1.5, 100)
    y_vals = -(w[0]*x_vals + b) / w[1]

    plt.plot(x_vals, y_vals, label="Decision Boundary")


# -----------------------------
# Plot AND Gate
# -----------------------------
plt.figure(figsize=(6,6))
plt.scatter(X[:,0], X[:,1], c=y_and, s=200)

plot_boundary(and_model, "AND")

plt.title("Perceptron â€” AND Gate")
plt.xlabel("Input 1")
plt.ylabel("Input 2")
plt.grid()
plt.show()

# -----------------------------
# Plot OR Gate
# -----------------------------
plt.figure(figsize=(6,6))
plt.scatter(X[:,0], X[:,1], c=y_or, s=200)

plot_boundary(or_model, "OR")

plt.title("Perceptron â€” OR Gate")
plt.xlabel("Input 1")
plt.ylabel("Input 2")
plt.grid()
plt.show()

# -----------------------------
# Print Model Parameters
# -----------------------------
print("\nAND Weights:", and_model.coef_)
print("AND Bias:", and_model.intercept_)

print("\nOR Weights:", or_model.coef_)
print("OR Bias:", or_model.intercept_)



----------------------------------------------------------------------------------

This program trains a Perceptron (single neuron) to learn:

AND gate
OR gate


and then shows the decision boundary visually.

ðŸ”¹ Step 1 â€” Import Libraries
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import Perceptron

âœ… Meaning

numpy â†’ create input arrays

matplotlib â†’ draw plots (spatial visualization)

Perceptron â†’ built-in perceptron model from sklearn

ðŸ”¹ Step 2 â€” Define Logic Gate Inputs
X = np.array([
    [0, 0],
    [0, 1],
    [1, 0],
    [1, 1]
])

âœ… Meaning

These are the 4 possible binary inputs:

Input1	Input2
0	0
0	1
1	0
1	1

This same input set is used for both AND and OR.

ðŸ”¹ Step 3 â€” Define Outputs (Targets)
y_and = np.array([0, 0, 0, 1])
y_or  = np.array([0, 1, 1, 1])

âœ… Meaning

These are the correct outputs:

AND Gate Truth Table
00 â†’ 0
01 â†’ 0
10 â†’ 0
11 â†’ 1

OR Gate Truth Table
00 â†’ 0
01 â†’ 1
10 â†’ 1
11 â†’ 1


These are what the perceptron must learn.

ðŸ”¹ Step 4 â€” Train Perceptron for AND Gate
and_model = Perceptron(max_iter=1000, eta0=0.1, random_state=0)
and_model.fit(X, y_and)

âœ… Meaning

We create and train a perceptron.

Parameters:

max_iter=1000 â†’ max training passes

eta0=0.1 â†’ learning rate

fit() â†’ train using AND outputs

During training perceptron:

adjusts weights
adjusts bias
until outputs match targets

ðŸ”¹ Step 5 â€” Train Perceptron for OR Gate
or_model = Perceptron(...)
or_model.fit(X, y_or)


Same process â€” but trained with OR truth table.

So now we have:

one perceptron for AND
one perceptron for OR

ðŸ”¹ Step 6 â€” Make Predictions
for inp, pred in zip(X, and_model.predict(X)):
    print(inp, "â†’", pred)

âœ… Meaning

We test the model on all inputs.

Example output:

[1 1] â†’ 1


Means perceptron correctly learned the gate.

ðŸ”¹ Step 7 â€” Decision Boundary Function
def plot_boundary(model, title):
    w = model.coef_[0]
    b = model.intercept_[0]

âœ… Meaning

Perceptron learns equation:

w1*x1 + w2*x2 + b = 0


This is a line â†’ decision boundary.

We extract:

weights (w)
bias (b)

Boundary Line Formula
y_vals = -(w[0]*x_vals + b) / w[1]


This converts perceptron equation into:

y = mx + c


So we can draw the separating line.

ðŸ”¹ Step 8 â€” Plot AND Gate
plt.scatter(X[:,0], X[:,1], c=y_and, s=200)
plot_boundary(and_model, "AND")

âœ… Meaning

Plot shows:

Points = inputs

Colors = class (0 or 1)

Line = perceptron boundary

This gives spatial understanding of how perceptron separates classes.

ðŸ”¹ Step 9 â€” Plot OR Gate

Same process â€” different learned boundary line.

ðŸ”¹ Step 10 â€” Print Weights & Bias
print(and_model.coef_)
print(and_model.intercept_)

âœ… Meaning

Shows learned parameters:

weights â†’ feature importance
bias â†’ threshold shift


Perceptron decision rule:

if wÂ·x + b â‰¥ 0 â†’ class 1
else â†’ class 0

ðŸ§  What Perceptron Is Doing Internally

For each training sample:

prediction = sign(wÂ·x + b)

if wrong:
    w = w + lr * x * error
    b = b + lr * error


Repeat until correct.

ðŸŽ¯ Why AND & OR Work

Because they are:

linearly separable


One straight line can separate classes.
